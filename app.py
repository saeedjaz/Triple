# app.py
# =========================================================
# Ù…Ù†ØµØ© TriplePower - Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø¨Ù†Ù…Ø· Ø§Ù„ØµÙˆØ±Ø© (ØµÙÙ‘Ø§Ù†: ÙŠÙˆÙ…ÙŠ + Ø£Ø³Ø¨ÙˆØ¹ÙŠ)
# Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ: Ù„Ø§ ÙŠÙØ´ØªØ±Ø· Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚Ø› ÙŠÙ…ÙƒÙ† ØªÙØ¹ÙŠÙ„ ÙÙ„ØªØ± Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠ Ø§Ø®ØªÙŠØ§Ø±ÙŠÙ‹Ø§
# =========================================================

import os
import re
from dotenv import load_dotenv
import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, date, timedelta
from html import escape
from zoneinfo import ZoneInfo  # Ù„Ø¶Ø¨Ø· Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„Ù…Ø­Ù„ÙŠ
import hashlib, secrets, base64  # ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙˆØ±

# =============================
# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
# =============================
load_dotenv()
SHEET_CSV_URL = os.getenv("SHEET_CSV_URL")

# Ø¥ÙŠÙ‚Ø§Ù Ø¢Ù…Ù† Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø¶Ø¨Ø· Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø©
if not SHEET_CSV_URL:
    st.error("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø¶Ø¨Ø· SHEET_CSV_URL ÙÙŠ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©. Ø£Ø¶ÙÙ‡ Ø«Ù… Ø£Ø¹Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„.")
    st.stop()

# =============================
# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø¹Ø§Ù…Ø© + Ø¯Ø¹Ù… RTL
# =============================
st.set_page_config(page_title="ğŸ”’ğŸ” ÙÙ„ØªØ± Ø§Ù„Ø§Ø´ØªØ±Ø§ÙƒØ§Øª ÙˆØ§Ø®ØªØ±Ø§Ù‚ Ø§Ù„Ø´Ù…ÙˆØ¹ | TriplePower", layout="wide")

# Ø­Ù‚Ù† CSS Ø¹Ø§Ù„Ù…ÙŠ Ù„Ø¬Ø¹Ù„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ RTL ÙÙŠ ÙƒØ§Ù…Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
RTL_CSS = """
<style>
  :root, html, body, .stApp { direction: rtl; }
  .stApp { text-align: right; }
  input, textarea, select { direction: rtl; text-align: right; }
  .stTextInput input, .stTextArea textarea, .stSelectbox div[role="combobox"],
  .stNumberInput input, .stDateInput input, .stMultiSelect [data-baseweb],
  label, .stButton button { text-align: right; }
  table { direction: rtl; }
  .stAlert { direction: rtl; }
</style>
"""
st.markdown(RTL_CSS, unsafe_allow_html=True)

# =============================
# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
# =============================

def linkify(text: str) -> str:
    """ØªØ­ÙˆÙŠÙ„ Ø£ÙŠ Ø±Ø§Ø¨Ø· Ù†ØµÙŠ Ø¥Ù„Ù‰ Ø±Ø§Ø¨Ø· Markdown Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù†Ù‚Ø±."""
    if not text:
        return ""
    pattern = r"(https?://[^\s]+)"
    return re.sub(pattern, r"[\1](\1)", text)

def load_important_links() -> str:
    """ØªØ­Ù…ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„Ù Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ù‡Ù…Ø© (Ø¥Ù† ÙˆÙØ¬Ø¯)."""
    try:
        with open("Ø±ÙˆØ§Ø¨Ø· Ù…Ù‡Ù…Ø©.txt", "r", encoding="utf-8") as f:
            content = f.read()
        return content
    except FileNotFoundError:
        return "âš ï¸ Ù…Ù„Ù 'Ø±ÙˆØ§Ø¨Ø· Ù…Ù‡Ù…Ø©.txt' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯."

def load_symbols_names(file_path: str, market_type: str) -> dict:
    """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ù…ÙˆØ³ (Ø§Ù„Ø±Ù…Ø² â†’ Ø§Ù„Ø§Ø³Ù…). ÙŠØ¯Ø¹Ù… Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©/Ø£Ù…Ø±ÙŠÙƒØ§."""
    mapping = {}
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                parts = line.split('\t', 1)
                if len(parts) == 2:
                    symbol, name = parts
                    if market_type == "Ø³Ø¹ÙˆØ¯ÙŠ":
                        mapping[symbol.strip()] = name.strip()
                    else:
                        mapping[symbol.strip().upper()] = name.strip()
        return mapping
    except Exception as e:
        st.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù {file_path}: {e}")
        return {}

# ===== ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙˆØ± (PBKDF2) =====
PBKDF_ITER = 100_000

def _pbkdf2_hash(password: str, salt: bytes | None = None) -> str:
    salt = salt or os.urandom(16)
    dk = hashlib.pbkdf2_hmac("sha256", password.encode("utf-8"), salt, PBKDF_ITER)
    return f"pbkdf2$sha256${PBKDF_ITER}${base64.b64encode(salt).decode()}${base64.b64encode(dk).decode()}"

def _pbkdf2_verify(password: str, stored: str) -> bool:
    try:
        algo, algoname, iters, b64salt, b64hash = stored.split("$", 4)
        if algo != "pbkdf2" or algoname != "sha256":
            return False
        iters = int(iters)
        salt = base64.b64decode(b64salt)
        expected = base64.b64decode(b64hash)
        test = hashlib.pbkdf2_hmac("sha256", password.encode("utf-8"), salt, iters)
        return secrets.compare_digest(test, expected)
    except Exception:
        return False

# ===== ÙƒØ§Ø´ Ù„ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† =====
@st.cache_data(ttl=600)
def load_users():
    df = pd.read_csv(SHEET_CSV_URL, dtype=str)
    return df.to_dict("records")

def check_login(username, password, users):
    username = (username or "").strip()
    password = (password or "")
    for u in users:
        if u.get("username") == username:
            pwd_hash = u.get("password_hash")
            if pwd_hash:  # Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø¢Ù…Ù†
                return u if _pbkdf2_verify(password, pwd_hash) else None
            # ØªÙˆØ§ÙÙ‚ Ø®Ù„ÙÙŠ Ù…Ø¹ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ…
            if u.get("password") == password:
                return u
    return None

def is_expired(expiry_date: str) -> bool:
    try:
        exp = datetime.strptime(expiry_date.strip(), "%Y-%m-%d").date()
        return exp < date.today()
    except Exception:
        return True

@st.cache_data(ttl=300)
def fetch_data(symbols, sd, ed, iv):
    """ØªÙ†Ø²ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† yfinance Ù„Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©."""
    if not symbols or not str(symbols).strip():
        return None
    try:
        return yf.download(
            tickers=symbols,
            start=sd,
            end=ed + timedelta(days=1),
            interval=iv,
            group_by="ticker",
            auto_adjust=True,
            progress=False,
            threads=True,
        )
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return None

def extract_symbol_df(batch_df: pd.DataFrame, code: str) -> pd.DataFrame | None:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ DataFrame Ù„Ø±Ù…Ø² Ù…Ø­Ø¯Ø¯ Ù…Ù† Ù†ØªÙŠØ¬Ø© yfinance Ø³ÙˆØ§Ø¡Ù‹ ÙƒØ§Ù†Øª MultiIndex (Ø¹Ø¯Ø© Ø±Ù…ÙˆØ²)
    Ø£Ùˆ DataFrame Ø£Ø¹Ù…Ø¯Ø© Ù…Ø³Ø·Ù‘Ø­Ø© (Ø±Ù…Ø² ÙˆØ§Ø­Ø¯).
    """
    if batch_df is None or batch_df.empty:
        return None
    try:
        if isinstance(batch_df.columns, pd.MultiIndex):
            lvl0 = batch_df.columns.get_level_values(0)
            if code in set(lvl0):
                return batch_df[code].reset_index()
            else:
                return None
        else:
            cols = set(map(str.lower, batch_df.columns.astype(str)))
            if {"open","high","low","close"}.issubset(cols):
                return batch_df.reset_index()
    except Exception:
        return None
    return None

def drop_last_if_incomplete(df: pd.DataFrame, tf: str, suffix: str, allow_intraday_daily: bool = False) -> pd.DataFrame:
    """Ø¥Ø³Ù‚Ø§Ø· Ø§Ù„Ø´Ù…Ø¹Ø© ØºÙŠØ± Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø© (Ù…Ø¹ Ø®ÙŠØ§Ø± Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ÙŠÙˆÙ…ÙŠ Ø§Ù„Ø­Ø§Ù„ÙŠ)."""
    if df is None or df.empty:
        return df
    dfx = df.copy()

    # Ù„Ùˆ ÙƒØ§Ù† Ø¢Ø®Ø± ØµÙ Ù†Ø§Ù‚Øµ Ù‚ÙŠÙ…Ø§Ù‹ (OHLC) Ù†Ø­Ø°ÙÙ‡
    if dfx.iloc[-1][["Open","High","Low","Close"]].isna().any():
        return dfx.iloc[:-1] if len(dfx) > 1 else dfx.iloc[0:0]

    last_dt = pd.to_datetime(dfx["Date"].iloc[-1]).date()

    if tf == "1d":
        if allow_intraday_daily:
            return dfx
        if suffix == ".SR":
            now = datetime.now(ZoneInfo("Asia/Riyadh"))
            after_close = (now.hour > 15) or (now.hour == 15 and now.minute >= 10)  # ØªØ¯Ø§ÙˆÙ„
            if last_dt == now.date() and not after_close:
                return dfx.iloc[:-1] if len(dfx) > 1 else dfx.iloc[0:0]
        else:
            now = datetime.now(ZoneInfo("America/New_York"))
            after_close = (now.hour > 16) or (now.hour == 16 and now.minute >= 5)  # Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ
            if last_dt == now.date() and not after_close:
                return dfx.iloc[:-1] if len(dfx) > 1 else dfx.iloc[0:0]
        return dfx

    if tf == "1wk":
        return dfx  # Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ ÙŠÙÙØ­Øµ ÙÙŠ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ù…Ù† Ø§Ù„ÙŠÙˆÙ…ÙŠ

    if tf == "1mo":
        now = datetime.now(ZoneInfo("Asia/Riyadh" if suffix == ".SR" else "America/New_York"))
        today = now.date()
        if last_dt.year == today.year and last_dt.month == today.month:
            return dfx.iloc[:-1] if len(dfx) > 1 else dfx.iloc[0:0]
        return dfx

    return dfx

# =============================
# Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© (Ù…Ø¹ Ø§Ø´ØªØ±Ø§Ø· "Ø¨ÙŠØ¹ÙŠØ© Ù…Ø¹ØªØ¨Ø±Ø©")
# =============================

def _qualify_sell55(c, o, h, l, pct=0.55):
    """
    Ù†Ø¹ØªØ¨Ø± Ø§Ù„Ø´Ù…Ø¹Ø© Ø§Ù„Ø¨ÙŠØ¹ÙŠØ© 55% "Ù…Ø¹ØªØ¨Ø±Ø©" Ø¥Ø°Ø§ ÙƒØ³Ø±Øª Ù‚Ø§Ø¹ Ø¢Ø®Ø± Ø´Ù…Ø¹Ø© Ø´Ø±Ø§Ø¦ÙŠØ© 55% (Ø§Ù„Ø¢Ù†).
    ÙŠÙ…ÙƒÙ† ØªÙˆØ³ÙŠØ¹ Ø§Ù„Ù…Ù†Ø·Ù‚ Ù„Ø§Ø­Ù‚Ù‹Ø§ Ù„ÙŠØ´Ù…Ù„ Ø§Ù„ÙƒØ³Ø± Ø¨Ù…Ø§ Ø¨Ø¹Ø¯Ù‡Ø§.
    """
    rng = (h - l)
    br = np.where(rng != 0, np.abs(c - o) / rng, 0.0)
    lose55 = (c < o) & (br >= pct) & (rng != 0)
    win55  = (c > o) & (br >= pct) & (rng != 0)

    # Ù†ØªØªØ¨Ù‘Ø¹ Ù‚Ø§Ø¹ Ø¢Ø®Ø± Ø´Ù…Ø¹Ø© Ø´Ø±Ø§Ø¦ÙŠØ© 55%
    last_win_low = np.full(c.shape, np.nan, dtype=float)
    cur_low = np.nan
    for i in range(len(c)):
        if win55[i]:
            cur_low = l[i]
        last_win_low[i] = cur_low

    valid_sell_now = lose55 & ~np.isnan(last_win_low) & (l <= last_win_low)
    return valid_sell_now, win55

def detect_breakout_with_state(df: pd.DataFrame, pct: float = 0.55) -> pd.DataFrame:
    """
    - Ø´Ø±Ø§Ø¡: Ø¥ØºÙ„Ø§Ù‚ > Ù‚Ù…Ø© Ø¢Ø®Ø± Ø´Ù…Ø¹Ø© Ø¨ÙŠØ¹ÙŠØ© "Ù…Ø¹ØªØ¨Ø±Ø©" 55%.
    - Ø®Ø±ÙˆØ¬: Ø¥ØºÙ„Ø§Ù‚ < Ù‚Ø§Ø¹ Ø¢Ø®Ø± Ø´Ù…Ø¹Ø© Ø±Ø§Ø¨Ø­Ø© 55%.
    - Ø¨Ø¹Ø¯ Ø§Ù„Ø®Ø±ÙˆØ¬: Ù†ØµÙØ± Ù…Ø±Ø¬Ø¹ Ø§Ù„Ø¨ÙŠØ¹ Ù„Ø¥Ø¬Ø¨Ø§Ø± Ø¸Ù‡ÙˆØ± Ø´Ù…Ø¹Ø© Ø¨ÙŠØ¹ÙŠØ© Ù…Ø¹ØªØ¨Ø±Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù‚Ø¨Ù„ Ø£ÙŠ Ø¯Ø®ÙˆÙ„ Ù„Ø§Ø­Ù‚.
    """
    if df is None or df.empty:
        return df

    o = df["Open"].values
    h = df["High"].values
    l = df["Low"].values
    c = df["Close"].values

    valid_sell55, win55 = _qualify_sell55(c, o, h, l, pct)

    state = 0
    states, first_buy_signals = [], []
    lose_high_55_const = np.nan   # Ù‚Ù…Ø© Ø¢Ø®Ø± Ø´Ù…Ø¹Ø© Ø¨ÙŠØ¹ÙŠØ© Ù…Ø¹ØªØ¨Ø±Ø©
    win_low_55_const   = np.nan   # Ù‚Ø§Ø¹ Ø¢Ø®Ø± Ø´Ù…Ø¹Ø© Ø±Ø§Ø¨Ø­Ø© 55%

    for i in range(len(df)):
        buy_sig  = (state == 0) and (not np.isnan(lose_high_55_const)) and (c[i] > lose_high_55_const)
        stop_sig = (state == 1) and (not np.isnan(win_low_55_const))   and (c[i] < win_low_55_const)

        if buy_sig:
            state = 1
            first_buy_signals.append(True)
        elif stop_sig:
            state = 0
            first_buy_signals.append(False)
            lose_high_55_const = np.nan  # Ù„Ø§ Ù†Ø³Ù…Ø­ Ø¨Ø¥Ø¹Ø§Ø¯Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚Ù…Ø© Ù‚Ø¯ÙŠÙ…Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø®Ø±ÙˆØ¬
        else:
            first_buy_signals.append(False)

        if valid_sell55[i]:
            lose_high_55_const = h[i]
        if win55[i]:
            win_low_55_const = l[i]

        states.append(state)

    df["State"] = states
    df["FirstBuySig"] = first_buy_signals
    df["LoseCndl55"] = valid_sell55
    df["WinCndl55"]  = win55
    return df

# =============================
# Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ/Ø§Ù„Ø´Ù‡Ø±ÙŠ Ù…Ù† Ø§Ù„ÙŠÙˆÙ…ÙŠ Ø§Ù„Ù…Ø¤ÙƒÙ‘ÙØ¯
# =============================

def _week_is_closed_by_data(df_daily: pd.DataFrame, suffix: str) -> bool:
    """ØªØ­Ù‚Ù‚ Ø¹Ù…Ù„ÙŠ Ù„Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ù…Ù† ØªÙˆÙÙ‘Ø± Ø¢Ø®Ø± Ø´Ù…Ø¹Ø© ÙŠÙˆÙ…ÙŠØ© Ù…Ø¤ÙƒØ¯Ø© Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯ Ø§Ù„Ø¥ØºÙ„Ø§Ù‚."""
    df = drop_last_if_incomplete(df_daily, "1d", suffix, allow_intraday_daily=False)
    if df is None or df.empty:
        return False
    tz = ZoneInfo("Asia/Riyadh" if suffix == ".SR" else "America/New_York")
    now = datetime.now(tz)
    last_dt = pd.to_datetime(df["Date"].iat[-1])
    if last_dt.date() < now.date():
        return True
    close_h, close_m = (15,10) if suffix==".SR" else (16,5)
    return (last_dt.date() == now.date()) and (now.hour > close_h or (now.hour == close_h and now.minute >= close_m))

def resample_weekly_from_daily(df_daily: pd.DataFrame, suffix: str) -> pd.DataFrame:
    """Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ù…Ù† Ø§Ù„ÙŠÙˆÙ…ÙŠ Ø§Ù„Ù…Ø¤ÙƒÙ‘ÙØ¯ + Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø¬Ø§Ø±ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙØºÙ„Ù‚."""
    if df_daily is None or df_daily.empty:
        return df_daily.iloc[0:0]

    df_daily = drop_last_if_incomplete(df_daily, "1d", suffix, allow_intraday_daily=False)
    if df_daily.empty:
        return df_daily.iloc[0:0]

    dfw = df_daily[["Date", "Open", "High", "Low", "Close"]].dropna().copy()
    dfw.set_index("Date", inplace=True)
    rule = "W-THU" if suffix == ".SR" else "W-FRI"
    dfw = dfw.resample(rule).agg({"Open": "first", "High": "max", "Low": "min", "Close": "last"}).dropna().reset_index()

    # Ø­Ø°Ù Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø§Ù„Ø¬Ø§Ø±ÙŠ Ø¥Ù† Ù„Ù… ÙŠÙØºÙ„Ù‚ Ø­Ø³Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if not _week_is_closed_by_data(df_daily, suffix) and not dfw.empty:
        dfw = dfw.iloc[:-1]
    return dfw

def resample_monthly_from_daily(df_daily: pd.DataFrame, suffix: str) -> pd.DataFrame:
    """Ø´Ù‡Ø±ÙŠ Ù…Ù† Ø§Ù„ÙŠÙˆÙ…ÙŠ Ø§Ù„Ù…Ø¤ÙƒÙ‘ÙØ¯ + Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø¬Ø§Ø±ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙØºÙ„Ù‚."""
    if df_daily is None or df_daily.empty:
        return df_daily.iloc[0:0]

    df_daily = drop_last_if_incomplete(df_daily, "1d", suffix, allow_intraday_daily=False)
    if df_daily.empty:
        return df_daily.iloc[0:0]

    dfm = df_daily[["Date", "Open", "High", "Low", "Close"]].dropna().copy()
    dfm.set_index("Date", inplace=True)
    dfm = dfm.resample("M").agg({"Open": "first", "High": "max", "Low": "min", "Close": "last"}).dropna().reset_index()

    tz = ZoneInfo("Asia/Riyadh" if suffix == ".SR" else "America/New_York")
    now = datetime.now(tz)
    if not dfm.empty and (dfm["Date"].iat[-1].year == now.year and dfm["Date"].iat[-1].month == now.month):
        dfm = dfm.iloc[:-1]
    return dfm

def weekly_state_from_daily(df_daily: pd.DataFrame, suffix: str) -> bool:
    df_w = resample_weekly_from_daily(df_daily, suffix)
    if df_w.empty:
        return False
    df_w = detect_breakout_with_state(df_w)
    return bool(df_w["State"].iat[-1] == 1)

def monthly_state_from_daily(df_daily: pd.DataFrame, suffix: str) -> bool:
    df_m = resample_monthly_from_daily(df_daily, suffix)
    if df_m.empty:
        return False
    df_m = detect_breakout_with_state(df_m)
    return bool(df_m["State"].iat[-1] == 1)

def monthly_first_breakout_from_daily(df_daily: pd.DataFrame, suffix: str) -> bool:
    """True Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¢Ø®Ø± Ø´Ù…Ø¹Ù‡ Ø´Ù‡Ø±ÙŠØ© (Ø§Ù„Ù…Ø¤ÙƒØ¯Ø©) Ø³Ø¬Ù‘Ù„Øª Ø£ÙˆÙ„ Ø§Ø®ØªØ±Ø§Ù‚ (FirstBuySig) Ø­Ø³Ø¨ Ù…Ù†Ø·Ù‚ 55%."""
    df_m = resample_monthly_from_daily(df_daily, suffix)
    if df_m is None or df_m.empty:
        return False
    df_m = detect_breakout_with_state(df_m)
    return bool(df_m["FirstBuySig"].iat[-1])

def generate_html_table(df: pd.DataFrame) -> str:
    html = """
    <style>
    table {border-collapse: collapse; width: 100%; direction: rtl; font-family: Arial, sans-serif;}
    th, td {border: 1px solid #ddd; padding: 8px; text-align: center;}
    th {background-color: #04AA6D; color: white;}
    tr:nth-child(even){background-color: #f2f2f2;}
    tr:hover {background-color: #ddd;}
    a {color: #1a73e8; text-decoration: none;}
    a:hover {text-decoration: underline;}
    .positive {background-color: #d4edda; color: #155724; font-weight: bold;}
    .negative {background-color: #f8d7da; color: #721c24; font-weight: bold;}
    </style>
    <table>
    <thead><tr>"""
    for col in df.columns:
        html += f"<th>{escape(col)}</th>"
    html += "</tr></thead><tbody>"
    status_cols = ["ÙŠÙˆÙ…ÙŠ", "Ø£Ø³Ø¨ÙˆØ¹ÙŠ", "Ø´Ù‡Ø±ÙŠ"]
    for _, row in df.iterrows():
        html += "<tr>"
        for col in df.columns:
            val = row[col]
            cell_class = ""
            if col in status_cols:
                if str(val).strip() == "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ":
                    cell_class = "positive"
                elif str(val).strip() == "Ø³Ù„Ø¨ÙŠ":
                    cell_class = "negative"
            if col == "Ø±Ø§Ø¨Ø· TradingView":
                safe_url = escape(val)
                html += f'<td><a href="{safe_url}" target="_blank" rel="noopener">{safe_url}</a></td>'
            else:
                html += f'<td class="{cell_class}">{escape(str(val))}</td>'
        html += "</tr>"
    html += "</tbody></table>"
    return html

# =============================
# Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù (Ù†Ù…Ø· Ø§Ù„ØµÙˆØ±Ø©)
# =============================

TF_LABELS = {"1d": "ÙŠÙˆÙ…ÙŠ", "1wk": "Ø£Ø³Ø¨ÙˆØ¹ÙŠ", "1mo": "Ø´Ù‡Ø±ÙŠ"}

def _last_valid_sell55_idx(df: pd.DataFrame) -> int | None:
    """Ø¢Ø®Ø± Ø´Ù…Ø¹Ø© Ø¨ÙŠØ¹ÙŠØ© Ù…Ø¹ØªØ¨Ø±Ø© 55% (Ù…Ø¤Ø´Ø± Ø§Ù„ØµÙ)."""
    if df is None or df.empty or "LoseCndl55" not in df.columns:
        return None
    idx = np.where(df["LoseCndl55"].values)[0]
    return int(idx[-1]) if len(idx) else None

def compute_tp_targets_from_last_sell(df_tf: pd.DataFrame) -> tuple[float, float, float, float] | None:
    """
    ÙŠØ­Ø³Ø¨: (start_above, t1, t2, t3) Ø¹Ù„Ù‰ ÙØ§ØµÙ„ Ù…Ø­Ø¯Ø¯.
    start_above = Ù‚Ù…Ø© Ø§Ù„Ø´Ù…Ø¹Ø© Ø§Ù„Ø¨ÙŠØ¹ÙŠØ© Ø§Ù„Ù…Ø¹ØªØ¨Ø±Ø©.
    tN = start_above + N * (Ù…Ø¯Ù‰ Ø§Ù„Ø´Ù…Ø¹Ø©).
    """
    if df_tf is None or df_tf.empty:
        return None
    for col in ["Open", "High", "Low", "Close"]:
        if col not in df_tf.columns:
            return None

    df_tf = detect_breakout_with_state(df_tf)  # ÙŠØ¶ÙŠÙ LoseCndl55
    i = _last_valid_sell55_idx(df_tf)
    if i is None:
        return None

    H = float(df_tf["High"].iat[i])
    L = float(df_tf["Low"].iat[i])
    R = H - L
    if not np.isfinite(R) or R <= 0:
        return None

    start_above = round(H, 2)
    t1 = round(H + 1 * R, 2)
    t2 = round(H + 2 * R, 2)
    t3 = round(H + 3 * R, 2)
    return start_above, t1, t2, t3

def _fmt_num(x):
    try:
        return f"{float(x):.2f}"
    except Exception:
        return "â€”"

def generate_targets_html_table(df: pd.DataFrame) -> str:
    """Ø¬Ø¯ÙˆÙ„ HTML Ù…ÙÙ„ÙˆÙ‘ÙÙ† ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©ØŒ ÙˆÙŠØªØ­Ù…Ù‘Ù„ Ù†Ù‚Øµ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…."""
    html = """
    <style>
      table {border-collapse: collapse; width: 100%; direction: rtl; font-family: Arial, sans-serif;}
      th, td {border: 1px solid #ddd; padding: 8px; text-align: center;}
      th {background-color: #04AA6D; color: white;}
      tr:nth-child(even){background-color: #f9f9f9;}
      tr:hover {background-color: #f1f1f1;}
      .positive {background-color: #d4edda; color: #155724; font-weight: bold;}
      .negative {background-color: #f8d7da; color: #721c24; font-weight: bold;}
    </style>
    <table><thead><tr>
    """
    from html import escape as _esc
    for col in df.columns:
        html += f"<th>{_esc(str(col))}</th>"
    html += "</tr></thead><tbody>"

    for _, r in df.iterrows():
        # ØªÙ„ÙˆÙŠÙ† Ø®Ø§Ù†Ø© "Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø­Ø±ÙƒØ©" ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø±Ù‚Ù…ÙŠØ©
        try:
            start_val = float(r["Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø­Ø±ÙƒØ© Ø¨Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø£Ø¹Ù„Ù‰"])
            cur_close = float(r["Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚"])
            row_cls = "positive" if cur_close >= start_val else "negative"
        except Exception:
            row_cls = ""

        html += "<tr>"
        for col in df.columns:
            val = r[col]
            cell_cls = row_cls if col == "Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø­Ø±ÙƒØ© Ø¨Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø£Ø¹Ù„Ù‰" else ""
            html += f'<td class="{cell_cls}">{_esc(str(val))}</td>'
        html += "</tr>"
    html += "</tbody></table>"
    return html

# =============================
# Ø¬Ù„Ø³Ø© Ø§Ù„Ø¹Ù…Ù„ (Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…)
# =============================
st.session_state.setdefault("authenticated", False)
st.session_state.setdefault("user", None)
st.session_state.setdefault("login_error", None)
st.session_state.setdefault("login_attempts", 0)

def do_login():
    if st.session_state.login_attempts >= 5:
        st.session_state.login_error = "too_many"
        return
    users = load_users()
    me = check_login(st.session_state.login_username, st.session_state.login_password, users)
    if me is None:
        st.session_state.login_attempts += 1
        st.session_state.login_error = "bad"
    elif is_expired(me.get("expiry","")):
        st.session_state.login_error = "expired"
    else:
        st.session_state.authenticated = True
        st.session_state.user = me
        st.session_state.login_error = None

# =============================
# Ø´Ø§Ø´Ø© ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„
# =============================
if not st.session_state.authenticated:
    col_left, col_right = st.columns([2, 1])
    with col_right:
        st.markdown('<h3 style="font-size:20px;">ğŸ”’ ØªØ³Ø¬ÙŠÙ„ Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ø´ØªØ±ÙƒÙŠÙ†</h3>', unsafe_allow_html=True)
        st.text_input("Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…", key="login_username", placeholder="Ø£Ø¯Ø®Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
        st.text_input("ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±", type="password", key="login_password", placeholder="Ø£Ø¯Ø®Ù„ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±")
        st.button("Ø¯Ø®ÙˆÙ„", on_click=do_login)
        if st.session_state.login_error == "bad":
            st.error("âš ï¸ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ùˆ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± ØºÙŠØ± ØµØ­ÙŠØ­Ø©.")
        elif st.session_state.login_error == "expired":
            st.error("âš ï¸ Ø§Ù†ØªÙ‡Ù‰ Ø§Ø´ØªØ±Ø§ÙƒÙƒ. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ¬Ø¯ÙŠØ¯.")
        elif st.session_state.login_error == "too_many":
            st.error("â›” ØªÙ… ØªØ¬Ø§ÙˆØ² Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§ Ù…Ø¤Ù‚ØªÙ‹Ø§. Ø­Ø§ÙˆÙ„ Ù„Ø§Ø­Ù‚Ù‹Ø§.")
    with col_left:
        important_links = load_important_links()
        st.markdown(
            "<div style='background-color:#f0f2f6;padding:20px;border-radius:8px;box-shadow:0 2px 5px rgb(0 0 0 / 0.1);line-height:1.6;'>"
            "<h3 style='font-size:20px;'>ÙÙ„ØªØ± Ù…Ù†ØµØ© Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ø«Ù„Ø§Ø«ÙŠØ© Ù„Ù„ØªØ¯Ø§ÙˆÙ„ ÙÙŠ Ø§Ù„Ø£Ø³ÙˆØ§Ù‚ Ø§Ù„Ù…Ø§Ù„ÙŠØ© TriplePower</h3>"
            + linkify(important_links) + "</div>",
            unsafe_allow_html=True,
        )
    st.stop()

# =============================
# ØªØ­Ù‚Ù‚ Ø¯ÙˆØ±ÙŠ Ù…Ù† Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ
# =============================
if is_expired(st.session_state.user["expiry"]):
    st.warning("âš ï¸ Ø§Ù†ØªÙ‡Ù‰ Ø§Ø´ØªØ±Ø§ÙƒÙƒ. ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø®Ø±ÙˆØ¬Ùƒ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§.")
    st.session_state.authenticated = False
    st.session_state.user = None
    st.rerun()

# =============================
# Ø¨Ø¹Ø¯ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„
# =============================
me = st.session_state.user
st.markdown("---")
with st.sidebar:
    # Ø¨Ø·Ø§Ù‚Ø© ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ
    st.markdown(
        f"""<div style="
            background-color:#28a745;padding:10px;border-radius:5px;color:white;
            font-weight:bold;text-align:center;margin-bottom:10px;">
            âœ… Ø§Ø´ØªØ±Ø§ÙƒÙƒ Ø³Ø§Ø±Ù Ø­ØªÙ‰: {me['expiry']}
            </div>""",
        unsafe_allow_html=True,
    )

    # ğŸ”” ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ Ø®Ù„Ø§Ù„ 3 Ø£ÙŠØ§Ù… Ø£Ùˆ Ø£Ù‚Ù„ (Ø¨Ø­Ø³Ø¨ ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø±ÙŠØ§Ø¶)
    try:
        expiry_dt = datetime.strptime(me["expiry"].strip(), "%Y-%m-%d").date()
        today_riyadh = datetime.now(ZoneInfo("Asia/Riyadh")).date()
        days_left = (expiry_dt - today_riyadh).days
        if 0 <= days_left <= 3:
            st.warning(f"âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: ØªØ¨Ù‚Ù‘Ù‰ {days_left} ÙŠÙˆÙ…Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø§Ø´ØªØ±Ø§Ùƒ. ÙŠÙØ±Ø¬Ù‰ Ø§Ù„ØªØ¬Ø¯ÙŠØ¯ Ù„ØªØ¬Ù†Ù‘Ø¨ Ø§Ù†Ù‚Ø·Ø§Ø¹ Ø§Ù„Ø®Ø¯Ù…Ø©.")
    except Exception:
        pass

    # Ø§Ø®ØªØ±Ø§Ù‚Ø§Øª Ø§Ù„Ø³Ø§Ø¹Ø© â€” Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ØºØ·
    st.markdown("### âš¡ Ø£Ø¨Ø±Ø² Ø§Ø®ØªØ±Ø§Ù‚Ø§Øª Ø§Ù„Ø³Ø§Ø¹Ø© ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ")
    show_intraday = st.checkbox("Ø¹Ø±Ø¶ Ø§Ø®ØªØ±Ø§Ù‚Ø§Øª Ø§Ù„Ø³Ø§Ø¹Ø© (ØªØ¬Ø±ÙŠØ¨ÙŠ)", value=False, help="Ù‚Ø¯ ÙŠØ¨Ø·Ø¦ Ø§Ù„ØªØ­Ù…ÙŠÙ„.")
    intraday_syms = """AAPL MSFT NVDA AMD TSLA META GOOGL AMZN NFLX AVGO QCOM TXN LRCX INTC MU ADI ORLY COST PEP PYPL QQQ""".split()

    @st.cache_data(ttl=300)
    def get_intraday_breakouts(symbols):
        data = fetch_data(" ".join(symbols), date.today()-timedelta(days=5), date.today(), "60m")
        out = []
        if data is None or (isinstance(data, pd.DataFrame) and data.empty):
            return out
        for s in symbols:
            try:
                df = extract_symbol_df(data, s)
                if df is None or df.empty:
                    continue
                df = detect_breakout_with_state(df)
                if not df.empty and bool(df["FirstBuySig"].iat[-1]):
                    out.append(s)
            except Exception:
                continue
        return out

    if show_intraday:
        breakout_list = get_intraday_breakouts(intraday_syms)
        st.sidebar.markdown(
            ", ".join([f"[{s}](https://www.tradingview.com/symbols/{s}/)" for s in breakout_list]) if breakout_list else "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø§Ø®ØªØ±Ø§Ù‚Ø§Øª Ø³Ø§Ø¹Ø© Ø­Ø§Ù„ÙŠØ§Ù‹."
        )
    else:
        st.sidebar.caption("ÙØ¹Ù‘Ù„ Ø§Ù„Ø®ÙŠØ§Ø± Ø£Ø¹Ù„Ø§Ù‡ Ù„Ø¹Ø±Ø¶Ù‡Ø§.")

    st.markdown("### âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„")
    market = st.sidebar.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø³ÙˆÙ‚", ["Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ", "Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ"])
    suffix = ".SR" if market == "Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ" else ""
    # Ø®ÙŠØ§Ø± Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ø§Ø´ØªØ±Ø§Ø· Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠ
    apply_triple_filter = st.sidebar.checkbox(
        "Ø§Ø´ØªØ±Ø§Ø· Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚ Ø§Ù„Ø«Ù„Ø§Ø«ÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)",
        value=False,
        help="Ø¹Ù†Ø¯ Ø§Ù„ØªÙØ¹ÙŠÙ„: ØªÙØ¹Ø±Ø¶ ÙÙ‚Ø· Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØªÙŠ ØªØ­Ù‚Ù‚ (Ø§Ø®ØªØ±Ø§Ù‚ ÙŠÙˆÙ…ÙŠ Ù…Ø¤ÙƒØ¯ + Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø¥ÙŠØ¬Ø§Ø¨ÙŠ + Ø£ÙˆÙ„ Ø§Ø®ØªØ±Ø§Ù‚ Ø´Ù‡Ø±ÙŠ). Ø¹Ù†Ø¯ Ø§Ù„ØªØ¹Ø·ÙŠÙ„: ØªÙØ¹Ø±Ø¶ ÙƒÙ„ Ø§Ù„Ø±Ù…ÙˆØ²."
    )

    start_date = st.sidebar.date_input("Ù…Ù†", date(2020, 1, 1))
    end_date = st.sidebar.date_input("Ø¥Ù„Ù‰", date.today())

    allow_intraday_daily = st.sidebar.checkbox(
        "ğŸ‘ï¸ Ø¹Ø±Ø¶ Ø§Ø®ØªØ±Ø§Ù‚Ø§Øª Ø§Ù„ÙŠÙˆÙ… Ù‚Ø¨Ù„ Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ (ÙŠÙˆÙ…ÙŠ) â€” Ù„Ù„Ø¹Ø±Ø¶ ÙÙ‚Ø·",
        value=False,
        help="Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙŠØ´ØªØ±Ø· Ø¥ØºÙ„Ø§Ù‚ ÙŠÙˆÙ…ÙŠ Ù…Ø¤ÙƒØ¯. Ù‡Ø°Ø§ Ø§Ù„Ø®ÙŠØ§Ø± Ù„Ø§ ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„ÙÙ„ØªØ±Ø©ØŒ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø£ÙŠ Ø¹Ø±Ø¶ Ø§Ø®ØªÙŠØ§Ø±ÙŠ.",
    )

    # Ø­Ø¬Ù… Ø§Ù„Ø¯ÙÙØ¹Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø¬Ù„Ø¨ (Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±Ù…ÙˆØ²)
    batch_size = st.sidebar.slider("Ø­Ø¬Ù… Ø§Ù„Ø¯ÙÙØ¹Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø¬Ù„Ø¨", min_value=20, max_value=120, value=60, step=10,
                                   help="ØªÙƒØ¨ÙŠØ±Ù‡Ø§ ÙŠØ³Ø±Ù‘Ø¹ Ø§Ù„Ø¬Ù„Ø¨ ÙˆÙ„ÙƒÙ† Ù‚Ø¯ ÙŠØ³ØªÙ‡Ù„Ùƒ Ø°Ø§ÙƒØ±Ø© Ø£ÙƒØ¨Ø±.")

    # ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡
    symbol_name_dict = (
        load_symbols_names("saudiSY.txt", "Ø³Ø¹ÙˆØ¯ÙŠ") if suffix == ".SR" else load_symbols_names("usaSY.txt", "Ø§Ù…Ø±ÙŠÙƒÙŠ")
    )

    if st.sidebar.button("ğŸ¯ Ø±Ù…ÙˆØ² ØªØ¬Ø±ÙŠØ¨ÙŠØ©"):
        st.session_state.symbols = "1120 2380 1050" if suffix == ".SR" else "AAPL MSFT GOOGL"
    try:
        with open("Ø±Ù…ÙˆØ² Ø§Ù„Ø§Ø³ÙˆØ§Ù‚ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©.xlsx", "rb") as file:
            st.sidebar.download_button(
                "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø±Ù…ÙˆØ² Ø§Ù„Ø£Ø³ÙˆØ§Ù‚",
                file,
                "Ø±Ù…ÙˆØ² Ø§Ù„Ø§Ø³ÙˆØ§Ù‚ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©.xlsx",
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
    except FileNotFoundError:
        st.sidebar.warning("âš ï¸ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹Ù‡ Ø¨Ø¬Ø§Ù†Ø¨ app.py")
    if st.sidebar.button("ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬"):
        st.session_state.authenticated = False
        st.session_state.user = None
        st.rerun()

# =============================
# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø±Ù…ÙˆØ²
# =============================
symbols_input = st.text_area("Ø£Ø¯Ø®Ù„ Ø§Ù„Ø±Ù…ÙˆØ² (Ù…ÙØµÙˆÙ„Ø© Ø¨Ù…Ø³Ø§ÙØ© Ø£Ùˆ Ø³Ø·Ø±)", st.session_state.get("symbols", ""))
symbols = [s.strip() + suffix for s in symbols_input.replace("\n", " ").split() if s.strip()]

# =============================
# ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„
# =============================
if st.button("ğŸ” ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„"):
    if not symbols:
        st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù…ÙˆØ² Ø£ÙˆÙ„Ù‹Ø§.")
        st.stop()

    with st.spinner("â³ Ù†Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ†Ø­Ø³Ø¨ Ø§Ù„Ø´Ø±ÙˆØ· ÙˆØ§Ù„Ø£Ù‡Ø¯Ø§Ù..."):
        results = []
        targets_rows = []

        total = len(symbols)
        prog = st.progress(0, text=f"Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„... (0/{total})")
        processed = 0

        # Ù†Ø¬Ù„Ø¨ ÙˆÙ†Ø¹Ø§Ù„Ø¬ Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        for i in range(0, total, batch_size):
            chunk_syms = symbols[i:i + batch_size]
            ddata_chunk = fetch_data(" ".join(chunk_syms), start_date, end_date, "1d")
            if ddata_chunk is None or (isinstance(ddata_chunk, pd.DataFrame) and ddata_chunk.empty):
                processed += len(chunk_syms)
                prog.progress(min(processed / total, 1.0), text=f"ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© {processed}/{total}")
                continue

            for code in chunk_syms:
                try:
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù„Ù„Ø±Ù…Ø² Ù…Ù† Ø§Ù„Ø¯ÙØ¹Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
                    df_d_raw = extract_symbol_df(ddata_chunk, code)
                    if df_d_raw is None or df_d_raw.empty:
                        continue

                    # ÙŠÙˆÙ…ÙŠ Ù…Ø¤ÙƒØ¯ ÙÙ‚Ø· (Ù„Ø§ Ù†Ø³Ù…Ø­ Ø¨Ù…Ø¹Ø§ÙŠÙ†Ø© Ù…Ø¨ÙƒØ±Ø© Ù‡Ù†Ø§ Ù„Ø£Ù†Ù‡ Ø´Ø±Ø· Ø£Ø³Ø§Ø³ÙŠ)
                    df_d_conf = drop_last_if_incomplete(
                        df_d_raw,
                        "1d",
                        suffix,
                        allow_intraday_daily=False,
                    )
                    if df_d_conf is None or df_d_conf.empty:
                        continue

                    # Ù…Ù†Ø·Ù‚ 55% Ø¹Ù„Ù‰ Ø§Ù„ÙŠÙˆÙ…ÙŠ Ø§Ù„Ù…Ø¤ÙƒØ¯
                    df_d = detect_breakout_with_state(df_d_conf)
                    if df_d is None or df_d.empty:
                        continue

                    # Ø­Ø§Ù„Ø§Øª Ø§Ù„ÙÙˆØ§ØµÙ„ (Ù„Ø§ Ù†ÙÙ„ØªØ± Ø¹Ù„ÙŠÙ‡Ø§ Ø¥Ù„Ø§ Ø¥Ø°Ø§ Ø·ÙÙ„Ø¨)
                    daily_positive    = bool(df_d["State"].iat[-1] == 1)
                    daily_first_break = bool(df_d["FirstBuySig"].iat[-1])
                    weekly_positive   = weekly_state_from_daily(df_d_conf, suffix)
                    monthly_first     = monthly_first_breakout_from_daily(df_d_conf, suffix)

                    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ± Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠ (Ø¥Ù† ØªÙ… ØªÙØ¹ÙŠÙ„Ù‡)
                    if apply_triple_filter:
                        if not (daily_first_break and weekly_positive and monthly_first):
                            continue  # ØªØ¬Ø§Ù‡Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø±Ù…Ø² Ø¹Ù†Ø¯ Ø§Ù„ÙÙ„ØªØ±Ø© Ø§Ù„ØµØ§Ø±Ù…Ø©

                    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¶
                    last_close = float(df_d["Close"].iat[-1])
                    sym = code.replace(suffix, '').upper()
                    company_name = (symbol_name_dict.get(sym, "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ") or "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")[:20]
                    tv = f"TADAWUL-{sym}" if suffix == ".SR" else sym
                    url = f"https://www.tradingview.com/symbols/{tv}/"

                    results.append(
                        {
                            "Ù…": 0,
                            "Ø§Ù„Ø±Ù…Ø²": sym,
                            "Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©": company_name,
                            "Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚": round(last_close, 2),
                            "ÙŠÙˆÙ…ÙŠ": "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ" if daily_positive else "Ø³Ù„Ø¨ÙŠ",
                            "Ø£Ø³Ø¨ÙˆØ¹ÙŠ": "Ø¥ÙŠØ¬Ø§Ø¨ÙŠ" if weekly_positive else "Ø³Ù„Ø¨ÙŠ",
                            "Ø´Ù‡Ø±ÙŠ": "Ø§Ø®ØªØ±Ø§Ù‚ Ø£ÙˆÙ„ Ù…Ø±Ø©" if monthly_first else "â€”",
                            "Ø±Ø§Ø¨Ø· TradingView": url,
                        }
                    )

                    # ===== Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù: ØµÙÙ‘Ø§Ù† (ÙŠÙˆÙ…ÙŠ + Ø£Ø³Ø¨ÙˆØ¹ÙŠ) =====
                    intervals_for_targets = ["1d", "1wk"]  # Ø£Ø¶ÙÙ "1mo" Ù„Ùˆ Ø£Ø±Ø¯Øª ØµÙÙ‹Ø§ Ø´Ù‡Ø±ÙŠÙ‹Ø§ Ø£ÙŠØ¶Ù‹Ø§
                    for tf in intervals_for_targets:
                        if tf == "1d":
                            df_tf = df_d_conf.copy()
                        elif tf == "1wk":
                            df_tf = resample_weekly_from_daily(df_d_conf, suffix)
                        else:
                            df_tf = resample_monthly_from_daily(df_d_conf, suffix)

                        tp = compute_tp_targets_from_last_sell(df_tf)
                        if tp is not None:
                            start_above, t1, t2, t3 = tp
                        else:
                            start_above = t1 = t2 = t3 = "â€”"  # Ù„Ø§ ØªÙˆØ¬Ø¯ Ø´Ù…Ø¹Ø© Ø¨ÙŠØ¹ÙŠØ© Ù…Ø¹ØªØ¨Ø±Ø© Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„ÙØ§ØµÙ„

                        targets_rows.append({
                            "Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©": company_name,
                            "Ø§Ù„Ø±Ù…Ø²": sym,
                            "Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚": round(last_close, 2),  # Ù†Ø¹Ø±Ø¶ Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„ÙŠÙˆÙ…ÙŠ ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ù…Ø«Ø§Ù„
                            "Ø§Ù„ÙØ§ØµÙ„": {"1d":"ÙŠÙˆÙ…ÙŠ","1wk":"Ø£Ø³Ø¨ÙˆØ¹ÙŠ","1mo":"Ø´Ù‡Ø±ÙŠ"}.get(tf, tf),
                            "Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø­Ø±ÙƒØ© Ø¨Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø£Ø¹Ù„Ù‰": start_above,
                            "Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø£ÙˆÙ„": t1,
                            "Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø«Ø§Ù†ÙŠ": t2,
                            "Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø«Ø§Ù„Ø«": t3,
                        })

                except Exception:
                    continue

            processed += len(chunk_syms)
            prog.progress(min(processed / total, 1.0), text=f"ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© {processed}/{total}")

        # ===== Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø±Ù…ÙˆØ² =====
        if results:
            df_results = pd.DataFrame(results)[
                ["Ù…", "Ø§Ù„Ø±Ù…Ø²", "Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©", "Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚", "ÙŠÙˆÙ…ÙŠ", "Ø£Ø³Ø¨ÙˆØ¹ÙŠ", "Ø´Ù‡Ø±ÙŠ", "Ø±Ø§Ø¨Ø· TradingView"]
            ]
            # ÙØ±Ø² ÙˆØªØ±Ù‚ÙŠÙ…
            df_results = df_results.sort_values(by="Ø§Ù„Ø±Ù…Ø²").reset_index(drop=True)
            df_results["Ù…"] = range(1, len(df_results) + 1)
            # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø³Ø¹Ø±
            df_results["Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚"] = df_results["Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚"].map(lambda x: f"{x:,.2f}")

            # ===== Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ =====
            market_name = "Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ" if suffix == ".SR" else "Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ"
            day_str = f"{end_date.day}-{end_date.month}-{end_date.year}"
            filt_note = "â€” ÙÙ„ØªØ±Ø© Ø¨Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚ Ù…ÙØ¹Ù‘Ù„Ø©" if apply_triple_filter else "â€” Ø¨Ø¯ÙˆÙ† Ø§Ø´ØªØ±Ø§Ø· Ø§Ù„Ø§Ø®ØªØ±Ø§Ù‚"

            with st.container():
                st.subheader(f"Ù†ØªØ§Ø¦Ø¬ ({market_name}) â€” {day_str} â€” Ø§Ù„Ø¹Ø¯Ø¯: {len(df_results)} {filt_note}")
                html_out = generate_html_table(df_results)
                st.markdown(html_out, unsafe_allow_html=True)

                # Ø£Ø²Ø±Ø§Ø± ØªÙ†Ø²ÙŠÙ„
                csv_bytes = df_results.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ CSV",
                    csv_bytes,
                    file_name=f"TriplePower_{('KSA' if suffix=='.SR' else 'USA')}_{day_str}.csv",
                    mime="text/csv"
                )
                st.download_button(
                    "ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ HTML",
                    html_out.encode("utf-8"),
                    file_name=f"TriplePower_{('KSA' if suffix=='.SR' else 'USA')}_{day_str}.html",
                    mime="text/html"
                )
        else:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±Ù…ÙˆØ² Ø¶Ù…Ù† Ù‚Ø§Ø¦Ù…ØªÙƒ Ù„Ø¹Ø±Ø¶Ù‡Ø§ (ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø£Ùˆ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª).")

        # ===== Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø¨Ù†Ù…Ø· Ø§Ù„ØµÙˆØ±Ø© =====
        if targets_rows:
            df_targets = pd.DataFrame(targets_rows)[
                ["Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©","Ø§Ù„Ø±Ù…Ø²","Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚","Ø§Ù„ÙØ§ØµÙ„","Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø­Ø±ÙƒØ© Ø¨Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø£Ø¹Ù„Ù‰","Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø£ÙˆÙ„","Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø«Ø§Ù†ÙŠ","Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø«Ø§Ù„Ø«"]
            ]
            # ØªØ±ØªÙŠØ¨: ÙŠÙˆÙ…ÙŠ Ø«Ù… Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ù„ÙƒÙ„ Ø±Ù…Ø²
            order_map = {"ÙŠÙˆÙ…ÙŠ": 0, "Ø£Ø³Ø¨ÙˆØ¹ÙŠ": 1, "Ø´Ù‡Ø±ÙŠ": 2}
            df_targets["_ord"] = df_targets["Ø§Ù„ÙØ§ØµÙ„"].map(order_map).fillna(9)
            df_targets = df_targets.sort_values(["Ø§Ù„Ø±Ù…Ø²", "_ord"]).drop(columns="_ord").reset_index(drop=True)

            # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ù…Ø¹ ØªØ­Ù…Ù‘Ù„ Ø§Ù„ÙØ±Ø§Øº
            for col in ["Ø³Ø¹Ø± Ø§Ù„Ø¥ØºÙ„Ø§Ù‚","Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø­Ø±ÙƒØ© Ø¨Ø§Ù„Ø¥ØºÙ„Ø§Ù‚ Ø£Ø¹Ù„Ù‰","Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø£ÙˆÙ„","Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø«Ø§Ù†ÙŠ","Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø«Ø§Ù„Ø«"]:
                df_targets[col] = df_targets[col].map(_fmt_num)

            st.markdown("### ğŸ¯ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù (TriplePower) â€” ÙŠÙˆÙ…ÙŠ + Ø£Ø³Ø¨ÙˆØ¹ÙŠ")
            html_targets = generate_targets_html_table(df_targets)
            st.markdown(html_targets, unsafe_allow_html=True)

            # ØªÙ†Ø²ÙŠÙ„
            st.download_button(
                "ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù CSV",
                df_targets.to_csv(index=False).encode("utf-8-sig"),
                file_name="TriplePower_Targets.csv",
                mime="text/csv"
            )
        else:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø¹Ù„Ù‰ Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©.")
